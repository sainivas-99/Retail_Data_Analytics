---
title: "Retail Data Analytics"
output: html_document
date: "2023-10-25"
---
```{r}
features_data <- read.csv("./Datasets/Features data set.csv",na.strings = "NA")
sales_data <- read.csv("./Datasets/sales data-set.csv")
stores_data  <- read.csv("./Datasets/stores data-set.csv")
```
```{r}
str(stores_data)
unique(stores_data$Type)
dim(stores_data)
```
```{r}
summary(stores_data)
```
#Data Preprocessing:
## Problems with Sales data:
  1. Type: Factor...?
```{r}
str(sales_data)
dim(sales_data)
```
```{r}
summary(sales_data)
```
##Problems with Sales data:
  1. Date : chr-> date : Done
  2. Weekly sales: why is the Weekly_Sales min a negative value?
  
##Solving for 1 in sales
```{r}
sales_data$Date <- as.Date(sales_data$Date, format = "%d/%m/%Y")
str(sales_data)
```
##Looking into 2 in sales:
```{r}
#View(sales_data)
```
The Weekly_sales have many negative values, so we can assume that this is due
to maybe returns or refunds to customers, theft or shrinkage or losses or maybe
due to promotional discounts. So we keep them as it is.
```{r}
head(features_data)
```

```{r}
str(features_data)
dim(features_data)
```
```{r}
summary(features_data)
```

## Problems with Features Data:
  1. Date column: chr -> date
  2. Markdown columns: have NA values, how to deal with them?
    a. Probably put it as zero, as the promotion is not available all time
       in all stores.
  3. CPI has NA values.
  4. Unemployment Rate has NA values, how to deal with them?

##Solving 1 for features: 
```{r}
features_data$Date <- as.Date(features_data$Date, format = "%d/%m/%Y")
summary(features_data$Date)
```
##Looking into 2 for features:
```{r}
MD1.na_count <- sum(is.na(features_data$MarkDown1))
MD1.na_count
```
```{r}
MD2.na_count <- sum(is.na(features_data$MarkDown2))
MD2.na_count
```
```{r}
MD3.na_count <- sum(is.na(features_data$MarkDown3))
MD3.na_count
```
```{r}
MD4.na_count <- sum(is.na(features_data$MarkDown4))
MD4.na_count
```
```{r}
MD5.na_count <- sum(is.na(features_data$MarkDown5))
MD5.na_count
```
```{r}
features_data$MarkDown1 <- ifelse(is.na(features_data$MarkDown1),0,
                                  features_data$MarkDown1)
features_data$MarkDown2 <- ifelse(is.na(features_data$MarkDown2),0,
                                  features_data$MarkDown2)
features_data$MarkDown3 <- ifelse(is.na(features_data$MarkDown3),0,
                                  features_data$MarkDown3)
features_data$MarkDown4 <- ifelse(is.na(features_data$MarkDown4),0,
                                  features_data$MarkDown4)
features_data$MarkDown5 <- ifelse(is.na(features_data$MarkDown5),0,
                                  features_data$MarkDown5)
```
```{r}
MD1.na_count <- sum(is.na(features_data$MarkDown1))
MD1.na_count
```
```{r}
MD2.na_count <- sum(is.na(features_data$MarkDown2))
MD2.na_count
```
```{r}
MD3.na_count <- sum(is.na(features_data$MarkDown3))
MD3.na_count
```
```{r}
MD4.na_count <- sum(is.na(features_data$MarkDown4))
MD4.na_count
```
```{r}
MD5.na_count <- sum(is.na(features_data$MarkDown5))
MD5.na_count
```

## Dealing with 3 in features
```{r}
CPI.na.count <- sum(is.na(features_data$CPI))
CPI.na.count
```
```{r}
Unemp.na.count <- sum(is.na(features_data$Unemployment))
Unemp.na.count
```
```{r}
library(dplyr)
cpi_features_data <- filter(features_data, !is.na(CPI)& !is.na(Unemployment))
cpi_features_data
```
When CPI is NA, then Unemployment is also NA. Gotta check this.
```{r}
cormatrix <- cor(cpi_features_data[,-2])
corrplot::corrplot(cormatrix, method = "number")
```
We noticed that there is a negative correlation of -0.3 between CPI and 
Unemployment, also we got to know that there is significant correlation 
between Markdown1 and Markdown4.

```{r}
str(stores_data)
```
```{r}
str(sales_data)
```

```{r}
head(stores_data)
```
```{r}
head(features_data)
```
```{r}
names(features_data)
names(sales_data)
```
```{r}
library(lubridate)
sales_data$Week <- week(sales_data$Date)
sales_data$Month <- month(sales_data$Date)
sales_data$Year <- year(sales_data$Date)
```
```{r}
head(sales_data)
```
```{r}
features_data$Week <- week(features_data$Date)
features_data$Month <- month(features_data$Date)
features_data$Year <- year(features_data$Date)
```
```{r}
head(features_data)
```
```{r}
summary(sales_data)
```
```{r}
filtered_sales <- sales_data %>% filter(Year %in% c(2010, 2011, 2012))
head(filtered_sales)
```


```{r}
weekly_sales_sum <- filtered_sales %>% group_by(Year, Week) %>%
  summarise(Total_Weekly_Sales = sum(Weekly_Sales))
head(weekly_sales_sum)
```


```{r}
library(ggplot2)
ggplot(weekly_sales_sum, aes(x = Week, y = Total_Weekly_Sales, color = factor(Year))) +
  geom_line() +
  labs(
    title = "Total Weekly Sales for 2010, 2011, and 2012"
  ) +
  scale_x_continuous(breaks = seq(0, 52, by = 4)) +
  scale_y_continuous(labels = scales::number_format(scale = 1e-3, suffix = "K"))+
  scale_color_discrete(name = "Year")
```
Weeks 6, 14, 26, 47, 51 have local maxima in the total sum over the years 2010, 2011
and 2012. The weeks 6, 47 and 51 are holiday weeks and hence have higher sales,
indicating a positive impact of holidays on sales.
```{r}
mean_monthly_sales <- filtered_sales %>% group_by(Year, Month) %>%
  summarise(Mean_Monthly_Sales = mean(Weekly_Sales))
head(mean_monthly_sales)
```
```{r}
ggplot(mean_monthly_sales, mapping = aes(x = Month, y = Mean_Monthly_Sales,
                                         color = factor(Year)))+
  geom_line()+
  labs(title = "Mean of Sales over weeks")+
  scale_x_continuous(breaks = seq(0, 12, by = 1))+
  scale_color_discrete(name = "Year")
```
The sales peaked at months 2, 6, 8 and are increasing in months 10-12, as these
have holidays. Moreover, the mean sales are comparably greater during months:
5 to 7 excluding holiday effect during the months 10-12. This is likely
indicating that the sales are higher during the summer.

```{r}
features_sales_merged <- merge(sales_data, features_data,
                               by = c("Store","Date","IsHoliday","Week",
                                      "Month","Year"))
merged_data <- merge(stores_data,features_sales_merged,
               by = "Store")
head(merged_data)
```
```{r}
# Fill NA/missing values with 0
merged_data[is.na(merged_data)] <- 0

# Print the first few rows of the dataframe
head(merged_data)

# Display information about the dataframe
str(merged_data)

# Display summary statistics of the dataframe
summary(merged_data)

# Sort the dataframe by 'Date'
merged_data <- merged_data[order(merged_data$Date), ]
```
```{r}
# Extract the 'Dept' column from the dataframe df
dept_list <- merged_data$Dept

# Convert to a list and get unique values
dept_list <- unique(dept_list)

# Convert the elements to strings
depts <- as.character(dept_list)

# Create a copy of depts
depts_res <- depts
```


```{r}
filter_dept_sales <- function(merged_data) {
  if (nrow(merged_data) == 0) {
    return("There are no records in the data frame")
  }
  
  merged_dept_val <- numeric(length(dept_list))
  
  for (i in seq_along(dept_list)) {
    merged_dept_val_add <- merged_data[merged_data$Dept == dept_list[i], ]
    val <- merged_dept_val_add$Weekly_Sales
    value <- mean(val, na.rm = TRUE)
    merged_dept_val[i] <- value
  }
  
  return(merged_dept_val)
}

```


```{r}
paint_graph <- function(merged_dept, depts) {
  merged_dept_val <- merged_dept
  depts <- depts

  # Sorting
  sorted_indices <- order(merged_dept_val, decreasing = TRUE)
  merged_dept_val <- merged_dept_val[sorted_indices]
  depts <- depts[sorted_indices]

  # Function to add labels
  autolabel <- function(rects, labels = NULL, height_factor = 1.5) {
    for (i in seq_along(rects)) {
      height <- rects[i]
      label <- ifelse(!is.null(labels), labels[i], as.character(height))
      # text(x = i, y = height * 0.98, label = label, pos = 3, offset = 0.05, cex = 0.7, col = "black")
    }
  }

  # Plotting
  barplot(merged_dept_val, names.arg = depts, col = "steelblue", main = "Sales by Department", xlab = "Sales", ylab = "Departments")
  autolabel(merged_dept_val, labels = depts, height_factor = 0.5)
}

```


```{r}
show_table_depts <- function(depts, val_no, val_have, dif, dif_part, mark) {
  table_mark_list <- data.frame('Department' = depts, "No markdown" = val_no, "There is a markdown mark category" = val_have, "With markdown - without markdown" = dif, "Percentage change" = dif_part)
  table_mark <- table_mark_list[order(table_mark_list$`Percentage change`, decreasing = TRUE), ]
  colnames(table_mark) <- c('Department', 'No markdown', paste('There is a markdown', mark, 'categories'), 'With markdown - without markdown', 'Percentage change')
  
  print(table_mark)
}

```

```{r}
paint_double_graph <- function(depts_res, y1, y2) {
  x1 <- seq(1, length(depts_res)) - 0.15
  x2 <- seq(1, length(depts_res)) + 0.25
  x3 <- seq(1, length(depts_res))
  y3 <- rep(0, length(depts_res))

  # Creating the plot
  par(mfrow = c(1, 1), mar = c(5, 10, 4, 2) + 0.1)
  barplot(y2, col = 'black', names.arg = depts_res, cex.names = 0.7, main = 'Sales by Department')
  barplot(y1, col = 'gray', add = TRUE)
  barplot(y3, col = 'white', add = TRUE)

  # Adding legend
  legend('topright', legend = c('With Defects', 'Without Defects'), fill = c('black', 'gray'))

  # Adding labels
  mtext('Sales', side = 1, line = 3, cex = 1.2)
  mtext('Departments', side = 2, line = 3, cex = 1.2)

  # Adjusting margins
  par(mar = c(5, 10, 4, 2) + 0.1)
}

```


```{r}
different <- function(have_mark, no_mark) {
  dif <- numeric(length(depts_res))
  for (i in seq_along(depts_res)) {
    dif_add <- have_mark[i] - no_mark[i]
    dif[i] <- dif_add
  }
  return(dif)
}
```


```{r}
different_part <- function(have_mark, no_mark) {
  dif_part <- numeric(length(depts_res))
  for (i in seq_along(depts_res)) {
    dif_add <- (have_mark[i] - no_mark[i]) / abs(no_mark[i] / 100)
    dif_part[i] <- dif_add
  }
  return(dif_part)
}

```


```{r}
# Assuming df is your data frame and depts_res is your departments vector
df_mark0 <- subset(merged_data, MarkDown1 == 0 & MarkDown2 == 0 & MarkDown3 == 0 & MarkDown4 == 0 & MarkDown5 == 0)
df_mark0_val <- filter_dept_sales(df_mark0)

# Graph output without markdowns
paint_graph(df_mark0_val, depts_res)

# Table output without markdowns
table_mark0 <- data.frame(
Department = depts_res, Sales = df_mark0_val)
table_mark0 <- table_mark0[order(table_mark0$Sales, decreasing = TRUE), ]

# Print the table
print(table_mark0)
```
```{r}
reserch_markdown <- function(number_MarkDown) {

  # Selection of records in which the values of markdowns of the nth type are greater than 0
  df_mark_have <- subset(merged_data, get(paste0("MarkDown", number_MarkDown)) > 0)


  # Determination of average weekly sales in the presence of markdown of the nth category
  df_markhave_val <- filter_dept_sales(df_mark_have)

  # Drawing a bar chart with sales figures before and after markdown
  paint_double_graph(depts_res, df_mark0_val, df_markhave_val)

  # Calculating changes
  dif_0have <- different(df_markhave_val, df_mark0_val)
  dif_part_0have <- different_part(df_markhave_val, df_mark0_val)

  
  depts <- lapply(depts_res, as.integer
               )
  depts_res <- unlist(depts)
  # Visual representation of changes
  # show_table_depts(depts_res, df_mark0_val, df_markhave_val, dif_0have, dif_part_0have, as.character(number_MarkDown))
  paint_graph(dif_0have, depts_res)
  paint_graph(dif_part_0have, depts_res)
}
```

```{r}
reserch_markdown(1)
```
# Figure 7. Holiday Reference for Corresponding Week Numbers

```{r, echo=FALSE}
# Create the Week column
merged_data$Week <- lubridate::week(merged_data$Date)
# Merge the holiday_table with the lookup table using IsHoliday as the k

# Convert the Date column to a Date format
merged_data$Date <- as.Date(merged_data$Date, format="%d/%m/%Y")

# Create the Week column
merged_data$Week <- lubridate::week(merged_data$Date)

# Create the Holiday_Ref column based on the specified holiday names
merged_data$Holiday_Ref <- ifelse(merged_data$Week == 6, "SuperBowl Week",
                           ifelse(merged_data$Week == 36, "LaborDay Week",
                           ifelse(merged_data$Week == 47|merged_data$Week == 48|
                                    merged_data$Week == 46, "ThanksGiving Week",
                           ifelse(merged_data$Week == 52, "Christmas Week", "Non Holiday Week"))))

# Print the updated merged_data
head(merged_data)
```

# Figure 7. Holiday Reference with their respecive weeks
```{r, echo=FALSE}
# Filter merged_data to include only rows with holidays
holiday_week_ref <- merged_data %>%
  filter(Holiday_Ref != "Non Holiday Week") %>%
  select(Week, Holiday_Ref) %>%
  distinct()
head(holiday_week_ref)
```
Fig. 7. Holiday Reference for Corresponding Week Numbers

# Figure 8. Weekely sales vs Stores

```{r, echo=FALSE}
# Weekly_Sales vs. Store
ggplot(merged_data, aes(x = Store, y = Weekly_Sales, color = Holiday_Ref)) +
  geom_point() +
  labs(title = "Weekly Sales vs. Store",
       x = "Store",
       y = "Weekly Sales") +
scale_color_manual(values = c("Non Holiday Week" = "blue", "SuperBowl Week" = "yellow",
                        "LaborDay Week" = "green", "ThanksGiving Week" = "red",
                        "Christmas Week" = "purple"))
```

The analysis of weekly sales across various stores reveals a prominent surge in sales during Thanksgiving Week (Week 47), suggesting a notable correlation between this holiday period and heightened purchasing activity. Additionally, a general upward trend in holiday sales is observed across most stores, indicating increased customer spending during these periods. While Thanksgiving Week stands out as a high-sales period, store-specific variations in performance during other holidays highlight opportunities for tailored marketing and strategic promotions. The findings suggest the importance of understanding both overarching trends and individual store dynamics for effective sales strategies.

# Figure 9. Weekely sales vs Temperature
```{r, echo=FALSE}
# Weekly_Sales vs. Temperature
ggplot(merged_data)+
geom_point(aes(x = Temperature,y = Weekly_Sales,color = Holiday_Ref),size=0.7)+
scale_y_continuous(labels = scales::number_format(scale = 1e-3,suffix = "K"))+
scale_color_manual(values = c("Non Holiday Week" = "blue", "SuperBowl Week" = "yellow",
                        "LaborDay Week" = "green", "ThanksGiving Week" = "red",
                        "Christmas Week" = "purple")) +
  labs(title = "Weekly Sales vs. Temperature",
       x = "Temperature",
       y = "Weekly Sales") 
```

The examination of the weekly sales in relation to temperature patterns revealed noteworthy aspects into consumer behavior. The majority of sales happens within a temperature range of 19 to 79 degrees. This indicate a preference for moderate climatic conditions. Further, holidays such as Christmas, SuperBowl, and ThanksGiving showed distinct temperature-sales correlations which saw Christmas and ThanksGiving having increased sales in the range of 17 to 65 degrees, which aligns with a preference for cooler weather during these festivities. The Labor Day, conversely, shows elevated sales in the warmer range of 55 to 90 degrees. Moreover, ThanksGiving proves to be a pivotal driver of high sales as compared to sales in other holidays, emphasizing the significance of strategic planning and targeted marketing efforts during this holiday. This analysis gives the importance of considering holiday dynamics and temperature variations in crafting effective sales strategies.


```{r}
filtered_features_sales_merged <- features_sales_merged %>% group_by(Date) %>%
  summarise(Weekly_Sales = mean(Weekly_Sales), Temperature = mean(Temperature),
            Fuel_Price = mean(Fuel_Price), CPI = mean(CPI),
            Unemployment = mean(Unemployment), IsHoliday = sum(IsHoliday))

filtered_features_sales_merged$IsHoliday <- ifelse(
  filtered_features_sales_merged$IsHoliday!=0, TRUE, FALSE)
head(filtered_features_sales_merged)
```

## Analysing relation b/w Date vs Weekly_Sales, Temperature, Fuel_Price, CPI
##and Unemployment
```{r}
library(gridExtra)
x_axis <- ggplot(filtered_features_sales_merged, aes(x = Date))
plot1 <- x_axis +
  geom_line(aes(y = Weekly_Sales)) 
  #geom_point(data = subset(data, IsHoliday == TRUE), aes(y = Weekly_Sales), shape = 4, color = "red") +
  #labs(title = "Weekly Sales/sales on Holiday")

plot2 <- x_axis +
  geom_line(aes(y = Temperature)) +
  labs(title = "Temperature")

plot3 <- x_axis +
  geom_line(aes(y = Fuel_Price)) +
  labs(title = "Fuel_Price")

plot4 <- x_axis +
  geom_line(aes(y = CPI)) +
  labs(title = "CPI")

plot5 <- x_axis +
  geom_line(aes(y = Unemployment)) +
  labs(title = "Unemployment")

grid.arrange(plot1, plot2, plot3, plot4, plot5)
```


```{r}
#Chatgpt provided optimized code
library(tidyr)
plot_sales_features <- gather(filtered_features_sales_merged, "attribs",
                     "Value", -Date, -IsHoliday) 

ggplot(plot_sales_features, aes(Date, Value)) + geom_line(aes(color = Value),
                                                          linewidth = 1) + facet_grid(attribs~., scales = "free_y",switch = "y") +
  ylab(NULL) + 
  theme(strip.background = element_blank(), strip.placement = "outside", 
        strip.text.y.left = element_text(angle = 0), legend.position = "none")+
        scale_x_date(date_breaks = "5 months", date_labels = '%Y-%m')
```

The below are the results of the analysis:
1. The Weekly Sales are higher at the end of year, especially in the months of
    Nov-Dec, but over the year it is not increased.
2. The Weekly Sales are higher nearby holidays.
3. Fuel Price and CPI shown growth over the years.
4. Unemployment decreased year after the year.
5. Temperature is showing a random walk.

```{r}
library(corrplot)
correlation_matrix <- cor(filtered_features_sales_merged[,
      c("Weekly_Sales", "Temperature", "Fuel_Price","IsHoliday", "CPI", 
        "Unemployment")])
corrplot(correlation_matrix, method = "number")
```
The below are the results of the analysis:
1. Weekly sales does not show any high correlation with any other parameters.
2. CPI and Unemployment shows negative correlation.
3. CPI and Fuel_Price are positively correlated.
4. Unemployment and Fuel_Price are negatively correlated.

##Analysing total yearly sales
```{r}
total_yearly_sales <- filtered_sales %>% group_by(Year) %>% 
                      summarise(Total_Sales = sum(Weekly_Sales))
head(total_yearly_sales)
```

```{r}
ggplot(total_yearly_sales,aes(x = Year, y = Total_Sales))+
  geom_bar(stat = "identity", fill = c("blue","orange","yellow"))+
  labs(title = "Total Sales vs Years")+
  scale_y_continuous(labels = scales::number_format(scale = 1e-6, suffix = "K"))
```

```{r}
plot1 <- ggplot(merged_data, mapping = aes(x = Type))+
  geom_bar(width = 0.3)+
  scale_y_continuous(labels = scales::number_format(scale = 1e-3, suffix = "K"))
plot2 <- ggplot(merged_data, mapping = aes(x = Type, y = Size))+
  geom_point()
plot3 <- ggplot(merged_data, mapping = aes(x = Type, y = Weekly_Sales))+
  geom_boxplot()+
  scale_y_continuous(limits = c(0, 6e4),
                  labels = scales::number_format(scale = 1e-3, suffix = "K"))
grid.arrange(plot1, plot2, plot3, nrow = 1)
```
The below are the results of the analysis:
1. Type A stores are the largest with highest sales, followed by B and then C.
2. We can notice a relationship between the size of retail stores and 
   the weekly sales, the bigger the size of the store, higher the weekly sales.


```{r}

```

